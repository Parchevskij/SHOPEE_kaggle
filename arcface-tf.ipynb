{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB3\nimport math\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet -q\nimport efficientnet.tfkeras as efn","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GET_CV = True\ndf = pd.read_csv('../input/shopee-product-matching/test.csv')\nif len(df) > 3:\n    GET_CV = False\ndel df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if GET_CV:\n    df = pd.read_csv('../input/shopee-product-matching/train.csv')\n    image_paths = '../input/shopee-product-matching/train_images/' + df['image']\nelse:\n    df = pd.read_csv('../input/shopee-product-matching/test.csv')\n    image_paths = '../input/shopee-product-matching/test_images/' + df['image']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 11014\nbatch_size = 32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_callback():\n    lr_start   = 0.000001\n    lr_max     = 0.000005 * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max    \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr_callback","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(tf.keras.layers.Layer):\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_embeddings(image_paths):\n    embeds = []\n    \n    margin = ArcMarginProduct(\n                n_classes = num_classes, \n                s = 30, \n                m = 0.5, \n                name='head/arc_margin', \n                dtype='float32'\n                )\n    inp = tf.keras.layers.Input(shape = (512, 512, 3), name = 'inp1')\n    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n    #x = EfficientNetB3(weights='imagenet', include_top = False)(inp)\n    x = efn.EfficientNetB3(weights='imagenet', include_top=False)(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = margin([x, label])\n        \n    output = tf.keras.layers.Softmax(dtype='float32')(x)\n\n    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n    model.load_weights('../input/effweigths/effnetb3_epf020_loss0.852.h5')\n\n    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n    chunk = 5000\n    iterator = np.arange(np.ceil(len(df) / chunk))\n    for j in iterator:\n        a = int(j * chunk)\n        b = int((j + 1) * chunk)\n        image_dataset = get_dataset(image_paths[a:b])\n        image_embeddings = model.predict(image_dataset)\n        embeds.append(image_embeddings)\n    del model\n    image_embeddings = np.concatenate(embeds)\n    print(f'Our image embeddings shape is {image_embeddings.shape}')\n    del embeds\n    #gc.collect()\n    return image_embeddings\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, (512, 512))\n    image = tf.cast(image, tf.float32) / 255.0\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_image(image):\n    image = tf.io.read_file(image)\n    image = decode_image(image)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\ndef get_dataset(image):\n    dataset = tf.data.Dataset.from_tensor_slices(image)\n    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n    dataset = dataset.batch(32)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text_embeddings(df, max_features = 15500):\n    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n    text_embeddings = model.fit_transform(df['title'])\n    print(f'Our title text embedding shape is {text_embeddings.shape}')\n    del model\n    return text_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_embeddings = get_image_embeddings(image_paths)\ntext_embeddings = get_text_embeddings(df, max_features = 15500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_neighbors(df, image_embeddings, text_embeddings, KNN = 100):\n    neighbors_model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine').fit(image_embeddings)\n    image_distances, image_indices = neighbors_model.kneighbors(image_embeddings)\n    neighbors_model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine').fit(text_embeddings)\n    text_distances, text_indices = neighbors_model.kneighbors(text_embeddings)\n  \n    if GET_CV:\n        predictions = []\n        for k in range(df.shape[0]):\n            idx_image = np.where(image_distances[k,] < 0.46)[0]\n            ids_image = image_indices[k,idx_image]\n            idx_text = np.where(text_distances[k,] < 0.30)[0]\n            ids_text = text_indices[k,idx_text]\n            ids = list(set(list(ids_image) + list(ids_text)))\n            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n            predictions.append(posting_ids)\n    \n    else:\n        predictions = []\n        for k in range(df.shape[0]):\n            idx_image = np.where(image_distances[k,] < 0.37)[0]\n            ids_image = image_indices[k,idx_image]\n            idx_text = np.where(text_distances[k,] < 0.21)[0]\n            ids_text = text_indices[k,idx_text]\n            ids = list(set(list(ids_image) + list(ids_text)))\n            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n            predictions.append(posting_ids)\n        \n    return df, predictions\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df, predictions = get_neighbors(df, image_embeddings, text_embeddings, KNN = 50)\ndf['matches'] = predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['posting_id', 'matches']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}